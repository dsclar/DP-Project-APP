h = h + geom_point(size = 6, colour = "black") + geom_point(size = 4)
h = h + xlab("Predictors: Horsepower+weight") + ylab("Miles per gallon")
h
h1 = h
h1 = h1 + geom_abline(intercept = coef(fitfno1)[1], slope = coef(fitfno1)[3], size = 2, color="salmon")
h1 = h1 + geom_abline(intercept = coef(fitfno1)[1] + coef(fitfno1)[4], slope = coef(fitfno1)[3], size = 2, color="turquoise")
h1
h = ggplot(mtcars, aes(x = wt, y = mpg, color = am))
h = h + geom_point(size = 6, colour = "black") + geom_point(size = 4)
h = h + xlab("Predictors: Weight") + ylab("Miles per gallon")
h
h1 = h
h1 = h1 + geom_abline(intercept = coef(fitfno1)[1], slope = coef(fitfno1)[3], size = 2, color="salmon")
h1 = h1 + geom_abline(intercept = coef(fitfno1)[1] + coef(fitfno1)[4], slope = coef(fitfno1)[3], size = 2, color="turquoise")
h1
?echo
g = ggpairs(mtcars, lower = list(continuous = "smooth"),params = c(method = "loess"))
g
all_fit=lm(mpg ~ ., data = mtcars); summary(all_fit); vif(all_fit)
fit0=lm(mpg~. -qsec-disp, data=mtcars); summary(fit0); vif(fit0)
fit1=lm(mpg~. -qsec-disp-gear, data=mtcars); summary(fit1); vif(fit1)
fit2=lm(mpg~. -qsec-disp-gear-drat, data=mtcars);summary(fit2); vif(fit2)
fit3=lm(mpg~. -qsec-disp-gear-drat-vs, data=mtcars);summary(fit3); vif(fit3)
fit4=update(fit3, mpg~.-qsec-disp-gear-drat-vs-carb); summary(fit4); vif(fit4)
fit5=update(fit4, mpg~.-hp-qsec-disp-gear-drat-vs-carb); summary(fit5); vif(fit5)
fit6=update(fit5, mpg~.-wt-hp-qsec-disp-gear-drat-vs-carb); summary(fit6); vif(fit6)
fit7=update(fit5, mpg~.-cyl-qsec-disp-gear-drat-vs-carb+hp); summary(fit7)$coef; vif(fit7)
anova( fit5, fit7)
anova(fit4, fit5, fit7)
anova(fit0, fit4, fit5, fit7)
anova(fit0, fit7)
anova(fit0: fit7)
all_fit=lm(mpg ~ ., data = mtcars); summary(all_fit); vif(all_fit)
fit0=lm(mpg~. -qsec-disp, data=mtcars); summary(fit0); vif(fit0)
fit1=update(fit0, mpg~. -qsec-disp-gear); summary(fit1); vif(fit1)
fit2=update(fit1, mpg~. -qsec-disp-gear-drat);summary(fit2); vif(fit2)
fit3=update(fit2, mpg~. -qsec-disp-gear-drat-vs);summary(fit3); vif(fit3)
fit4=update(fit3, mpg~.-qsec-disp-gear-drat-vs-carb); summary(fit4); vif(fit4)
fit5=update(fit4, mpg~.-hp-qsec-disp-gear-drat-vs-carb); summary(fit5); vif(fit5)
fit6=update(fit5, mpg~.-wt-hp-qsec-disp-gear-drat-vs-carb); summary(fit6); vif(fit6)
fit7=update(fit5, mpg~.-cyl-qsec-disp-gear-drat-vs-carb+hp); summary(fit7)$coef; vif(fit7)
anova(fit0: fit7)
anova(fit0,fit1, fit2, fit3, fit4, fit5, fit6, fit7)
fitfno1=lm(mpg~hp+wt+am, data=mtcars[-c(17, 20),])
summary(fitfno1)$coef
?t.test
library(dplyr)
mtcars$am=as.character(mtcars$am)
mtcars$am[mtcars$am=="0"]="Automatic"; mtcars$am[mtcars$am=="1"]="Manual"; mtcars$am=factor(mtcars$am)
Summary_Table=summarise(group_by(mtcars, am), avg_mpg=mean(mpg), sd_mpg=sd(mpg), se_mpg=sd(mpg)/sqrt(length(am)), var_mpg=sd(mpg)^2)
t.test(mpg~am, data=mtcars, var.equal=T)# variance considered equal
Avg_automatic=t.test(mpg~am, data=mtcars)$estimate[1]; Avg_manual=t.test(mpg~am, data=mtcars)$estimate[2]
PVal=t.test(mpg~am, data=mtcars)$p.value
Avg_automatic
Avg_manual
PVal=t.test(mpg~am, data=mtcars)$p.value
PVal
Avg_automatic=t.test(mpg~am, data=mtcars)$estimate[2, 1]; Avg_manual=t.test(mpg~am, data=mtcars)$estimate[2, 2]
Avg_automatic=mean(mpg, am=="Automatic
Avg_automatic=mean(mpg, am=="Automatic)
summary(fitfno1)$coef
h = ggplot(mtcars, aes(x = wt, y = mpg, color = am))
h = h + geom_point(size = 6, colour = "black") + geom_point(size = 4)
h = h + xlab("Predictors: Weight") + ylab("Miles per gallon") + geom_abline(intercept = coef(fitfno1)[1], slope = coef(fitfno1)[3], size = 2, color="salmon") + geom_abline(intercept = coef(fitfno1)[1] + coef(fitfno1)[4], slope = coef(fitfno1)[3], size = 2, color="turquoise"); h
mtcars$am=factor(mtcars$am)
summary(fitfno1)$coef
h = ggplot(mtcars, aes(x = wt, y = mpg, color = am))
h = h + geom_point(size = 6, colour = "black") + geom_point(size = 4)
h = h + xlab("Predictors: Weight") + ylab("Miles per gallon") + geom_abline(intercept = coef(fitfno1)[1], slope = coef(fitfno1)[3], size = 2, color="salmon") + geom_abline(intercept = coef(fitfno1)[1] + coef(fitfno1)[4], slope = coef(fitfno1)[3], size = 2, color="turquoise"); h
mtcars$am=factor(mtcars$am)
summary(fitfno1)$coef
h = ggplot(mtcars, aes(x = wt, y = mpg, color = am))
h = h + geom_point(size = 6, colour = "black") + geom_point(size = 4)
h = h + xlab("Predictors: Weight") + ylab("Miles per gallon") + geom_abline(intercept = coef(fitfno1)[1], slope = coef(fitfno1)[3], size = 2, color="salmon") + geom_abline(intercept = coef(fitfno1)[1] + coef(fitfno1)[4], slope = coef(fitfno1)[3], size = 2, color="turquoise"); h
?anova
anova(fit0,fit1, fit2, fit3, fit4, fit5, fit6, fit7)
str(d)
d=anova(fit0,fit1, fit2, fit3, fit4, fit5, fit6, fit7)
d=anova(fit0,fit1, fit2, fit3, fit4, fit5, fit6, fit7)
str(d)
str(anova(fit0,fit1, fit2, fit3, fit4, fit5, fit6, fit7))
summary(anova(fit0,fit1, fit2, fit3, fit4, fit5, fit6, fit7))$Pr(>F)[8]
summary(anova(fit0,fit1, fit2, fit3, fit4, fit5, fit6, fit7))$Pr[8]
summary(anova(fit0,fit1, fit2, fit3, fit4, fit5, fit6, fit7))$p.value[8]
summary(anova(fit0,fit1, fit2, fit3, fit4, fit5, fit6, fit7))$p.value
summary(anova(fit0,fit1, fit2, fit3, fit4, fit5, fit6, fit7))
* R squared adjusted was `r summary(fitfno1)$adj.r.squared`. Variance inflation coefficients were lower than in previous models, `r vif(fitfno1)`.
library(swirl)
swirl()
x1c<-simbias()
apply(x1c, 1, mean)
fit1<-lm(Fertility~Agriculture)
fit1<-lm(Fertility~Agriculture, data=swiss)
fit3<-lm(Fertility~Agriculture + Examination+Education, data=swiss)
anova(fit1, fit3)
deviance(fit3)
d<-deviance(fit3)/43
n<-deviance(fit1)-deviance(fit3)
n<-deviance(fit1)-deviance(fit3)/2
n<-(deviance(fit1)-deviance(fit3))/2
n/d
pf(n/d, 2, 43, lower.tail=FALSE)
shapiro.test(fit3$residuals)
anova(fit1, fit3, fit5, fit6)
swirl()
view(ravenData)
View(ravenData)
mdl<-glm(ravenWinNum~ravenScore, family="binomial", ravenData)
lodds<-predict(mdl, data.frame(ravenScore=c(0, 3, 6))
lodds<-predict(mdl, data.frame(ravenScore=c(0, 3, 6)))
exp(lodds)/(1+exp(lodds))
summary(mdl)
exp(confint(mdl))
anova(mdl)
qchisq(.95, 1)
var(rpois(1000, 50))
nxt()
head(hits)
class(hits$Date)
class(hits$date)
as.interger(head(hits[,'date'])
as.interger(head(hits[,'date']))
as.integer(head(hits[,'date']))
mdl<-glm(visits~date, poisson, hits))
mdl<-glm(visits~date, poisson, hits)
summary(mdl)
exp(confint(mdl, 'date'))
which.max(hits[,'visits'])
hits[704,]
lambda<-mdl$fitted.values[704]
qpois(.95, lambda)
mdl2<-
?glm
mdl2<-glm(visits~date, offset=log(visits+1), family=poisson)
mdl2<-glm(visits~date, data=hits, offset=log(visits+1), family=poisson)
mdl2<-glm(simplystats~date, data=hits, offset=log(visits+1), family=poisson)
qpois(.95, mdl24fitted.values[704])
qpois(.95, mdl2$fitted.values[704])
?shuttle
library(MASS)
?glm
head(shuttle)
sh=glm(use~wind, data=shuttle, family="binomial")
summary(sh)
exp(sh)$coef
exp(sh$coef)
sh2=glm(use~wind+magn, data=shuttle, family="binomial")
summary(sh2)
exp(sh2$coef)
sh2=glm(use~wind*magn, data=shuttle, family="binomial")
summary(sh2)
exp(sh2$coef)
library(dplyr)
sht=mutate(shuttle, autolander=use-1)
View(sht)
shuttle$use[shuttle$use=="auto"]=1
shuttle$use[shuttle$use=="noauto"]=0
View(shuttle)
data(shuttle)
head(shuttle)
shuttle$use=as.character(shuttle$use)
shuttle$use[shuttle$use=="auto"]=1
shuttle$use[shuttle$use=="noauto"]=0
shuttle$use=as.numeric(shuttle$use)
mutate(shuttle, use=use-1)
sh=glm(use~wind, data=shuttle, family="binomial")
summary(sh)
data(InsectSprays)
data(InsectSprays)
head(InsectSprays)
?glm
q4_pois=glm(count~spray, family="poisson", data= InsectSprays)
summary(q4_pois)
exp(q4_pois$coef)
log(q4_pois$coef)
q4_pois=glm(count+1~spray, family="poisson", data= InsectSprays)
summary(q4_pois)
exp(q4_pois$coef)
log(q4_pois$coef)
q4_pois1=lm(count~spray, data= InsectSprays)
summary(q4_pois1)
exp(coef(lm(I(log(count +1))~spray, data= InsectSprays))
exp(coef(lm(I(log(count +1))~spray, data= InsectSprays)))
exp(coef(lm(I(log(count +1))~spray, data= InsectSprays)))
q4_pois=glm(count~spray, family="poisson", offset=log(count+1), data= InsectSprays)
summary(q4_pois)
?poisson
q5_pois=glm(count~spray+offset(t), family="poisson", data= InsectSprays)
summary(q5_pois)
t=1
t2=log(10)+t
q5_pois=glm(count~spray+ offset(t2), family="poisson", data= InsectSprays)
summary(q5_pois)
?offset
x=-5:5
y <- c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.9
x=-5:5
y <- c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.97)
x=-5:5
y <- c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.97)
plot(x, y)
q6_lm=lm(y~x)
summary(q6_lm)
q6_lm=lm(y~0)
q6_lm=lm(y~0)
summary(q6_lm)
x=-5:5
y <- c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.97)
knots= -5:5
splineterms=sapply(knots, function(knot) (x>knot)*(x-knot))
xMat=cbind(1, x, splineterms)
yhat=predict(lm(y~xMat))
plot(x, y)
lines(x, yhat, col="red", lwd=2)
q6_lm=lm(y~xMat)
summary(q6_lm)
q6_lm=lm(y~xMat+knots)
q6_lm=lm(y~xMat+knots)
summary(q6_lm)
library(MASS)
data(shuttle)
sh2=glm(use~wind+magn, data=shuttle, family="binomial")
summary(sh2)
exp(sh2$coef)
sh=glm(use~wind, data=shuttle, family="binomial")
summary(sh)
exp(sh$coef)
data(InsectSprays)
head(InsectSprays)
q4_pois=glm(count~spray, family="poisson", data= InsectSprays)
summary(q4_pois)
exp(q4_pois$Coef)
exp(q4_pois$coef)
t=3.178
t2=log(10)+t
q5_pois=glm(count~spray+ offset(t2), family="poisson", data= InsectSprays)
summary(q5_pois)
x=-5:5
y <- c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.97)
knots= -5:5
splineterms=sapply(knots, function(knot) (x>knot)*(x-knot))
xMat=cbind(1, x, splineterms)
yhat=predict(lm(y~xMat))
plot(x, y)
lines(x, yhat, col="red", lwd=2)
sh2=glm(use~wind+magn, data=shuttle, family="binomial")
summary(sh2)
exp(sh2$coef)
library(caret)
set.seed(1235)
modelFit2 <- train(type ~.,data=training, method="glm")
modelFit2
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
library(Hmisc)
library(ggplot2)
View(concrete)
?concrete
View(concrete)
View(mixtures)
summary(mixtures)
cutCS=cut2(training$CompressiveStrength, g=3)
featurePlot(x=training[,c("FlyAsh", "Age")]), y=training$CompressiveStrength,
plot="pairs")
featurePlot(x=training[,c("FlyAsh", "Age")], y=training$CompressiveStrength,
plot="pairs")
qplot(Age, CompressiveStrength, data=training)
qplot(Age, CompressiveStrength, colour= FlyAsh, data=training)
qq=qplot(FlyAsh, CompressiveStrength, colour= Age, data=training)
qq+geom_smooth(method='lm', formula=y~x)
qq=qplot(Cemment, CompressiveStrength, colour= Age, data=training)
qq+geom_smooth(method='lm', formula=y~x)
qq=qplot(Cement, CompressiveStrength, colour= Age, data=training)
qq+geom_smooth(method='lm', formula=y~x)
table(cutCS)
p1=qplot(cutCS, cement, data=training, fill=cutSC, geom=c("boxplot"))
p1
p1=qplot(cutCS, cement, data=training, fill=cutCS, geom=c("boxplot"))
p1
p1=qplot(cutCS, Cement, data=training, fill=cutCS, geom=c("boxplot"))
p1
p2=qplot(cutCS, Cement, data=training, fill=cutCS, geom=c("boxplot", "jitter"))
grid.arrange(p1, p2, ncol=2)
?grid
p2=qplot(cutCS, Cement, data=training, fill=cutCS, geom=c("boxplot", "jitter"))
grid(p1, p2, ncol=2)
p1=qplot(cutCS, Cement, data=training, fill=cutCS, geom=c("boxplot"))
p2=qplot(cutCS, Cement, data=training, fill=cutCS, geom=c("boxplot", "jitter"))
grid(p1, p2, ncol=2)
?grid.arrange
??grid.arrange
?par
par(mfcol=c(1,2))
p1=qplot(cutCS, Cement, data=training, fill=cutCS, geom=c("boxplot"))
p2=qplot(cutCS, Cement, data=training, fill=cutCS, geom=c("boxplot", "jitter"))
par(mfcol=c(1,2))
library(ggplot2)
p2=qplot(cutCS, Cement, data=training, fill=cutCS, geom=c("boxplot", "jitter"))
p1=qplot(cutCS, Cement, data=training, fill=cutCS, geom=c("boxplot"))
p1=qplot(cutCS, Cement, data=training, fill=cutCS, geom=c("boxplot"))
p1=qplot(cutCS, Cement, data=training, fill=cutCS, geom=c("boxplot"))
#Q2
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
library(ggplot2)
library(Hmisc)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
cutCS=cut2(training$CompressiveStrength, g=3)
table(cutCS)
p1=qplot(cutCS, Cement, data=training, fill=cutCS, geom=c("boxplot"))
p2=qplot(cutCS, Cement, data=training, fill=cutCS, geom=c("boxplot", "jitter"))
p1=qplot(cutCS, Cement, data=training, fill=cutCS, geom=c("boxplot"))
qq=qplot(Cement, CompressiveStrength, colour= Age, data=training)
qq+geom_smooth(method='lm', formula=y~x)
p1=qplot(cutCS, Cement, data=training, fill=cutCS, geom=c("boxplot"))
grid.arrange(p1, p2, ncol=2)
table(cutCS)
p1=qplot(cutCS, Cement, data=training, fill=cutCS, geom=c("boxplot"))
install.packages("utility")
p1=qplot(cutCS, Cement, data=training, fill=cutCS, geom=c("boxplot"))
p2=qplot(cutCS, Cement, data=training, fill=cutCS, geom=c("boxplot", "jitter"))
grid.arrange(p1, p2, ncol=2)
qplot(CompressiveStrength, colour=Cement, data=training, geom="density")
qplot(CompressiveStrength, colour=Age, data=training, geom="density")
qplot(Age, CompressiveStrength, colour= FlyAsh, data=training)
qq=qplot(Cement, CompressiveStrength, colour= Age, data=training)
qq+geom_smooth(method='lm', formula=y~x)
qplot(Age, CompressiveStrength, data=training)
qplot(CompressiveStrength, colour=Age, data=training
qplot(CompressiveStrength, colour=Age, data=training)
qplot(CompressiveStrength, colour=Age, data=training)
hist(training$SuperPlasticizer)
hist(training$Superplasticizer)
hist(log(training$Superplasticizer+1))
mean(training$Superplasticizer)
sd(training$Superplasticizer)
trainSP=training$Superplasticizer
trainSPSt=(trainSP-mean(trainSP)/sd(trainSP)
mean(trainSPSt)
trainSP=training$Superplasticizer
trainSPSt=(trainSP-mean(trainSP))/sd(trainSP)
mean(trainSPSt)
sd(trainSPst)
mean(trainSPSt)
sd(trainSPSt)
testSP=testing$Superplasticizer
testSPSt=(testSP-mean(trainSP))/sd(trainSP)
mean(testSPSt)
sd(testSPSt)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
nearZeroVar(training, saveMetrics=T)
library(dplyr)
?AlzheimerDisease
?AlzheimerDisease
?AlzheimerDisease
select(training, c(diagnosis, IL_11:IL_8))
Az=select(training, c(diagnosis, IL_11:IL_8))
?train
View(training)
table(training$diagnosis)
?dummyVars
modelFit=train(Az$diagnosis ~ ., method ="glm", preProcess="pca", data=Az)
?glm
library(caret)
View(Az)
View(training)
library(AppliedPredictiveModeling)
install.packages("Appli")
install.packages("minqa")
modelFit=train(Az$diagnosis ~ ., method ="glm", preProcess="pca", data=Az)
?train
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
nearZeroVar(training, saveMetrics=T)
library(dplyr)
Az=select(training, c(diagnosis, IL_11:IL_8))
table(training$diagnosis)
install.packages("devtools")
devtools::install_github('rstudio/shinyapps')
shinyapps::setAccountInfo(name='dsclar', token='325CEEBDF25E63E814869F1D26930F5D', secret='ecW4fsGQE4bNJNZRYzSlkNByV6tmJpAQ3nu9nUw9')
library(shinyapps)
shinyapps::deployApp('path/to/your/app')
library(shinyapps)
shinyapps::deployApp()
install_github("ropensci/plotly")
library(devtools)
install_github("ropensci/plotly")
library(plotly)
load("courseraData.rda")
set_credentials_file("dsclar", "wpa0fsokf9")
ggiris <- qplot(Petal.Width, Sepal.Length, data = iris, color = Species)
ggiris
py=plotly()
r=py$ggplotly(ggiris)
r$response$url
library(manipulate)
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
manipulate((myPlot(s), s=slider(0,2, step=0.1))
manipulate(myPlot(s), s=slider(0,2, step=0.1))
library(rCharts)
dTable(airquality, sPaginationType= "full_numbers")
runApp(display.mode="showcase")
shiny::runApp('Data Products/App_Quizz1Q5')
shiny::runApp('Data Products/App_Quizz1Q5')
# Requires presence of credentials.txt file containing login/password in the following format:
# UserName=my_username&Password=my_password
COMPETITION=diabetic-retinopathy-detection
all: download_files
session.cookie: credentials.txt
curl -o /dev/null -c session.cookie https://www.kaggle.com/account/login
curl -o /dev/null -c session.cookie -b session.cookie -L -d @credentials.txt https://www.kaggle.com/account/login
files.txt: session.cookie
curl -c session.cookie -b session.cookie -L http://www.kaggle.com/c/$(COMPETITION)/data | \
grep -o \"[^\"]*\/download[^\"]*\" | sed -e 's/"//g' -e 's/^/http:\/\/www.kaggle.com/' > files.txt
download_files: files.txt session.cookie
mkdir -p files
cd files && xargs -n 1 curl -b ../session.cookie -L -O < ../files.txt
.PHONY: clean
clean:
rm session.cookie files.txt files/*.zip
setwd("C:/Users/Anne-Catherine/Documents/Data Products/DP-Project")
library(dplyr)
set.seed(100)
Questions=c("bother", "poor_appetite", "get_off_blue", "good_as_others", "pb_focusing", "depressed",
"effortful", "hopeful", "failure", "fearful", "restless_sleep", "happy", "less_talk", "lonely",
"unfriendly_people", "enjoy_life", "crying", "sad", "disliked", "no_get_going")
a=lapply(Questions, function(x) x=rbinom(1000, size= 3, prob=.45))
df_CES_D=data.frame(a)
colnames(df_CES_D)= c(Questions)
df_CES_D[c(4, 8, 12, 16)]=df_CES_D[c(4, 8, 12, 16)]-3
sumB=apply(df_CES_D, 1, sum)
df_CES_D=mutate(df_CES_D, Score_D=sumB)
Status=ifelse(df_CES_D$Score_D > 16, 1, 0)
df_CES_D=mutate(df_CES_D, Status=Status)
ndep=sum(df_CES_D$Status)
Mean_Status=t.test(Score_D~Status, data=df_CES_D)$estimate[2] - t.test(Score_D~Status, data=df_CES_D)$estimate[1]
P_value_Status=t.test(Score_D~Status, data=df_CES_D)$p.value
library(caret); library(dplyr)
set.seed(101)
df_CES_D=select_(df_CES_D, -21)
inTrain <- createDataPartition(y=df_CES_D$Status,
p=0.66, list=FALSE)
CES_training_set <- df_CES_D[inTrain,]
CES_validation_set <- df_CES_D[-inTrain,]
set.seed(3)
modelFitLM = train(CES_training_set$Status ~ ., method="lm", data=CES_training_set, trControl=trainControl(method="cv", number=10))
modelFitLM$finalModel
modelFitLM$varImp
modelFitLM$results
modelFitLM$coefficients
summary(modelFitLM)
pred = predict(modelFitLM,CES_validation_set); CES_validation_set$predRight = round(pred)==CES_validation_set$Status
Confusion_Matrix=table(round(pred),CES_validation_set$Status)
valAccuracy=round(sum(diag(Confusion_Matrix))/(nrow(CES_validation_set)),2)
summ=summary(modelFitLM)
pvalues=as.data.frame(summ$coefficients[, c(1, 4)])
row.names(pvalues)
pvalues=arrange_(pvalues, pvalues[,4], Estimate)
pvalues=arrange_(pvalues, pvalues[,2], Estimate)
View(pvalues)
pvalues=arrange_(pvalues, pvalues[2], Estimate)
pvalues=arrange_(pvalues, pvalues$Pr(>|t|), Estimate)
pvalues=arrange_(pvalues, Estimate)
?arrange
pvalues[with(pvalues, order(Estimate)),]
pvalues[with(pvalues, order(desc(Estimate))),]
pvalues[1:6,]
pvalues=pvalues[with(pvalues, order(desc(Estimate))),]
pvalues[1:6,]
pvalues=pvalues[with(pvalues, order(desc(Estimate, Pr(>|t|)))),]
pvalues=pvalues[with(pvalues, order(desc(Estimate, p.values))),]
pvalues=pvalues[with(pvalues, order(desc(Estimate, p.value))),]
pvalues=pvalues[with(pvalues, order(desc(Estimate))),]
pvalues=pvalues[with(pvalues, order(desc(Estimate))),]
pvalues[1:5,]
top=pvalues[1:5,]
top
summ=summary(modelFitLM)
coef=as.data.frame(summ$coefficients[, c(1, 4)])
row.names(coef)
coef=coef[with(coef, order(desc(Estimate))),]
top=coef[1:5,]
top
top=coef[1:5,1]
top
top=coef[1:5,]
top
